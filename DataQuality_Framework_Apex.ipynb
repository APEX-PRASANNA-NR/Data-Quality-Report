{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages and modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connector Packages:\n",
    "from snowflake.snowpark.session import Session\n",
    "import openpyxl\n",
    "\n",
    "#ML Packages:\n",
    "from config import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "\n",
    "#Other Packages:\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising the required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "excel_columns = [\"COLUMN_NAME\",]\n",
    "\n",
    "db_name = input(\"DATABASE NAME : \").upper()\n",
    "schema_name = input(\"SCHEMA NAME : \").upper()\n",
    "\n",
    "workbook = openpyxl.Workbook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect with the Snowflake to read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snowpark_session():\n",
    "  conn_params = {\n",
    "      \"account\" : \"pr91731-production_northeurope\",\n",
    "      \"user\" : input(\"Username : \"),\n",
    "      \"password\" : input(\"Password : \"),\n",
    "      \"database\" : db_name,     \n",
    "      \"role\" : \"DATAENGINEER\",\n",
    "      \"warehouse\" : \"INGESTION_WH\"\n",
    "  }\n",
    "\n",
    "  session = Session.builder.configs(conn_params).create()\n",
    "\n",
    "  return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpark = snowpark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_excel_file(worksheet,summary):\n",
    "    row = 2\n",
    "    \n",
    "    #Adding heading\n",
    "    for excel_column_name in excel_columns:\n",
    "        # print(excel_column_name,end=\" \")\n",
    "        worksheet.cell(row = 1, column = excel_columns.index(excel_column_name)+1, value = excel_column_name)\n",
    "    # print()\n",
    "    for column in summary.keys():\n",
    "        # print(column,end=\" > \")\n",
    "        worksheet.cell(\n",
    "            row = row, \n",
    "            column = 1,\n",
    "            value = column.lower()\n",
    "        )\n",
    "        \n",
    "        calculations = summary[column]\n",
    "        \n",
    "        for metric in calculations.keys():\n",
    "            column = excel_columns.index(metric) + 1\n",
    "            # print(\"\\n\\t\",column,\" - \",calculations[metric],end=\"\")\n",
    "            if(isinstance(calculations[metric],str)):\n",
    "                cal = calculations[metric].lower()\n",
    "            else:\n",
    "                cal = calculations[metric]\n",
    "            \n",
    "            worksheet.cell(\n",
    "                row = row, \n",
    "                column = column, \n",
    "                value = cal\n",
    "            )\n",
    "        row += 1\n",
    "        # print()\n",
    "    return worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(report,indent = 0,start_delimiter = \"[\",end_delimiter = \"]\",seperator = \" -> \"):    \n",
    "    if(isinstance(report,list)):\n",
    "        val = \"\"\n",
    "        val += start_delimiter\n",
    "        for value in report:\n",
    "            if(report.index(value) == len(report)-1):\n",
    "                val += str(value)\n",
    "            else:\n",
    "                val += str(value)+\", \"\n",
    "        val+= end_delimiter\n",
    "        print(indent+val)\n",
    "    \n",
    "    elif(isinstance(report,str)):\n",
    "        print('\"'+report+'\"')\n",
    "    \n",
    "    \n",
    "    elif(isinstance(report,dict)):\n",
    "        for key,value in report.items():\n",
    "            space = indent*'\\t'\n",
    "            print(f\"{space}{key} {seperator} \",end=\"\")\n",
    "            if(isinstance(value,dict) or isinstance(value,list) or isinstance(value,tuple) or isinstance(value,set)):\n",
    "                indent += 1\n",
    "                print(\"\")\n",
    "                show(indent = indent,report = value)\n",
    "                indent -=1\n",
    "            elif(isinstance(value,str)):\n",
    "                show(indent = indent,report = value)\n",
    "            else:\n",
    "                print(f\"{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def data_quality_check(table_name):\n",
    "  try:\n",
    "    #collecting the data structure(Datatype)/schematics of the table for identifying the \n",
    "    ddl = snowpark.sql(f\"DESCRIBE TABLE {db_name}.{schema_name}.{table_name}\").collect()\n",
    "    data = snowpark.sql(f'SELECT * FROM {db_name}.{schema_name}.{table_name}')\n",
    "    data.show()\n",
    "\n",
    "    for row in ddl: \n",
    "      \n",
    "      #Initialising column name for future reference\n",
    "      col = '\"'+row[\"name\"]+'\"'\n",
    "      summary[col] = {}\n",
    "      \n",
    "      print(data[col])\n",
    "      \n",
    "      #FINDING THE DATA TYPE OF THE COLUMN\n",
    "      summary[col][\"DATA_TYPE\"] = row[\"type\"]\n",
    "      if(\"DATA_TYPE\" not in excel_columns):\n",
    "        excel_columns.append(\"DATA_TYPE\")\n",
    "      \n",
    "      #FINDING THE NULL COUNT IN EACH COLUMN\n",
    "      summary[col][\"NULL_COUNT\"] = data.filter(data[col].isNull()).count()\n",
    "      if(\"NULL_COUNT\" not in excel_columns):\n",
    "        excel_columns.append(\"NULL_COUNT\")\n",
    "      \n",
    "      #FINDING THE TOTAL COUNT IN EACH COLUMN\n",
    "      summary[col][\"TOTAL_COUNT\"] = data.count()\n",
    "      if(\"TOTAL_COUNT\" not in excel_columns):\n",
    "        excel_columns.append(\"TOTAL_COUNT\")\n",
    "      \n",
    "      #FINDING THE NOT-NULL COUNT IN EACH COLUMN\n",
    "      summary[col][\"NOT_NULL_COUNT\"] = summary[col][\"TOTAL_COUNT\"] - summary[col][\"NULL_COUNT\"]\n",
    "      if(\"NOT_NULL_COUNT\" not in excel_columns):\n",
    "        excel_columns.append(\"NOT_NULL_COUNT\")\n",
    "      \n",
    "      #FINDING THE UNIQUE(DISTINCT) VALUE COUNT IN EACH COLUMN\n",
    "      summary[col][\"UNIQUE_COUNT\"] = data.select(col).distinct().count() - 1\n",
    "      if(\"UNIQUE_COUNT\" not in excel_columns):\n",
    "        excel_columns.append(\"UNIQUE_COUNT\")\n",
    "        \n",
    "      #FINDING THE REPEARING/DUPLICATE VALUE COUNT IN EACH COLUMN EXCLUDING THE UNIQUE COUNT\n",
    "      summary[col][\"DUPLICATE\"] = summary[col][\"NOT_NULL_COUNT\"] - summary[col][\"UNIQUE_COUNT\"]\n",
    "      if(\"DUPLICATE\" not in excel_columns):\n",
    "        excel_columns.append(\"DUPLICATE\")\n",
    "      \n",
    "      if(\"NUMBER\" in summary[col][\"DATA_TYPE\"] or \"FLOAT\" in summary[col][\"DATA_TYPE\"]):\n",
    "        try:\n",
    "          quartile = data.approx_quantile(col,[0.25,0.75])\n",
    "\n",
    "          summary[col][\"Q1\"] = Q1 = quartile[0]\n",
    "          if(\"Q1\" not in excel_columns):\n",
    "            excel_columns.append(\"Q1\")\n",
    "          summary[col][\"Q3\"] = Q3 = quartile[1]\n",
    "          if(\"Q3\" not in excel_columns):\n",
    "            excel_columns.append(\"Q3\")\n",
    "\n",
    "          summary[col][\"IQR\"] = IQR = Q3-Q1\n",
    "          if(\"IQR\" not in excel_columns):\n",
    "            excel_columns.append(\"IQR\")\n",
    "\n",
    "          summary[col][\"LOWER_LIMIT\"] = lower_limit = Q1 - 1.5 * IQR\n",
    "          if(\"LOWER_LIMIT\" not in excel_columns):\n",
    "            excel_columns.append(\"LOWER_LIMIT\")\n",
    "          summary[col][\"UPPER_LIMIT\"] = upper_limit = Q3 + 1.5 * IQR\n",
    "          if(\"UPPER_LIMIT\" not in excel_columns):\n",
    "            excel_columns.append(\"UPPER_LIMIT\")\n",
    "\n",
    "          summary[col][\"OUTLIERS\"] = outliers = data.filter((data[col] < lower_limit) | (data[col] > upper_limit)).count()\n",
    "          if(\"OUTLIERS\" not in excel_columns):\n",
    "            excel_columns.append(\"OUTLIERS\")\n",
    "        \n",
    "        except Exception as e:\n",
    "          print(\"Error in calculating the Number data type\",e)\n",
    "          \n",
    "      elif(\"BOOLEAN\" in summary[col][\"DATA_TYPE\"]):\n",
    "        try:\n",
    "          if(summary[col][\"UNIQUE_COUNT\"] > 2):\n",
    "            summary[col][\"MISCELLANEOUS_COUNT\"] = summary[col][\"UNIQUE_COUNT\"] - 2\n",
    "            if(\"MISCELLANEOUS_COUNT\" not in excel_columns):\n",
    "              excel_columns.append(\"MISCELLANEOUS_COUNT\")\n",
    "          \n",
    "          else:\n",
    "            summary[col][\"MISCELLANEOUS_COUNT\"] = 0\n",
    "            if(\"MISCELLANEOUS_COUNT\" not in excel_columns):\n",
    "              excel_columns.append(\"MISCELLANEOUS_COUNT\")\n",
    "        \n",
    "        except Exception as e:\n",
    "          print(\"Error in calculating the Boolean data type\",e)\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"Error in calculating common data types - \",e)\n",
    "  \n",
    "  return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"Company\"                                  |\"Client Account\"                      |\"SF/FF Client Account ID\"  |\"Entity Name\"                               |\"FF Entity Code\"  |\"Customer\"  |\"Client Group Name\"  |\"Region\"    |\"GLA\"                           |\"Acquired date\"  |\"DIM 1\"  |\"Year\"  |\"Currency\"  |\"Jan\"     |\"Feb\"     |\"Mar\"     |\"Apr\"  |\"May\"  |\"Jun\"  |\"Jul\"  |\"Aug\"  |\"Sep\"  |\"Oct\"  |\"Nov\"  |\"Dec\"  |\"Total Revenue\"  |\"CompanyCode\"  |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|APEX CORPORATE SERVICES (IRELAND) LIMITED  |STRATUS II CAPITAL DAC                |A59998                     |STRATUS II CAPITAL DAC                      |F15078            |CG30092     |STRATUS CAPITAL PLC  |EUROPE      |4730-36 SPV ADMINISTRATION      |2019.0           |CAPM     |2022    |USD         |2083.33   |2083.34   |2083.33   |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |6250.0           |ACSCIL         |\n",
      "|APEX CORPORATE SERVICES (IRELAND) LIMITED  |CLOVERTREE ASSET HOLDINGS DAC         |A61398                     |CLOVERTREE ASSET HOLDINGS DAC               |F15954            |CG12359     |CLOVERTREE           |EUROPE      |4730-36 SPV ADMINISTRATION      |2019.0           |CAPM     |2022    |USD         |0.0       |2588.99   |0.0       |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |2588.99          |ACSCIL         |\n",
      "|APEX CORPORATE SERVICES (IRELAND) LIMITED  |CLOVERTREE ASSET HOLDINGS DAC         |A61398                     |CLOVERTREE ASSET HOLDINGS DAC               |F15954            |CG12359     |CLOVERTREE           |EUROPE      |4730-36 SPV ADMINISTRATION      |2019.0           |CAPM     |2022    |USD         |22557.06  |22781.12  |23781.12  |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |69119.3          |ACSCIL         |\n",
      "|APEX CORPORATE SERVICES (IRELAND) LIMITED  |ARGON CAPITAL PLC                     |A21823                     |ARGON CAPITAL PLC                           |F5290             |CG30087     |ARGON CAPITAL PLC    |EUROPE      |4300-10 DISBURSEMENTS           |2019.0           |CSEC     |2022    |USD         |1105.32   |0.0       |0.0       |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |1105.32          |ACSCIL         |\n",
      "|THROGMORTON UK LIMITED                     |FIONA MCCALLUM                        |MCCAF                      |FIONA MCCALLUM                              |MCCAF             |CG32200     |FIONA MCCALLUM       |LINK_THROG  |NULL                            |2021.0           |BUSS     |2022    |USD         |0.0       |-254.14   |0.0       |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |-254.14          |THUKL          |\n",
      "|APEX CORPORATE SERVICES (IRELAND) LIMITED  |SOCA JERSEY LIMITED                   |A68911                     |SECURITISATION OF CATALOGUE ASSETS LIMITED  |F16623            |CG12798     |SOCA JERSEY LIMITED  |EUROPE      |4730-36 SPV ADMINISTRATION      |NULL             |CAPM     |2022    |USD         |915.08    |915.09    |915.08    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |2745.25          |ACSCIL         |\n",
      "|APEX FUND SERVICES (CAYMAN) LTD            |APEX FUND SERVICES (HK) LIMITED (KY)  |A74161                     |XIANG H1 MANAGEMENT CO., LIMITED (KY)       |F22554            |CG10163     |APEX GROUP           |AMERICAS    |4700-26 REGISTERED OFFICE FEES  |2005.0           |CLSD     |2022    |USD         |115.95    |115.95    |115.95    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |347.85           |AFSCYL         |\n",
      "|APEX FUND SERVICES (CAYMAN) LTD            |APEX FUND SERVICES (HK) LIMITED (KY)  |A74161                     |XIANG H14 MANAGEMENT CO., LIMITED (KY)      |F22555            |CG10163     |APEX GROUP           |AMERICAS    |4700-26 REGISTERED OFFICE FEES  |2005.0           |CLSD     |2022    |USD         |115.95    |115.95    |115.95    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |347.85           |AFSCYL         |\n",
      "|APEX FUND SERVICES (CAYMAN) LTD            |APEX FUND SERVICES (HK) LIMITED (KY)  |A74161                     |XIANG H15 MANAGEMENT CO., LIMITED (KY)      |F22557            |CG10163     |APEX GROUP           |AMERICAS    |4700-26 REGISTERED OFFICE FEES  |2005.0           |CLSD     |2022    |USD         |115.95    |115.95    |115.95    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |347.85           |AFSCYL         |\n",
      "|APEX FUND SERVICES (CAYMAN) LTD            |APEX FUND SERVICES (HK) LIMITED (KY)  |A74161                     |XIANG H16 MANAGEMENT CO., LIMITED (KY)      |F22558            |CG10163     |APEX GROUP           |AMERICAS    |4700-26 REGISTERED OFFICE FEES  |2005.0           |CLSD     |2022    |USD         |115.95    |115.95    |115.95    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |0.0    |347.85           |AFSCYL         |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Column[\"Company\"]\n",
      "Column[\"Client Account\"]\n",
      "Column[\"SF/FF Client Account ID\"]\n",
      "Column[\"Entity Name\"]\n",
      "Column[\"FF Entity Code\"]\n",
      "Column[\"Customer\"]\n",
      "Column[\"Client Group Name\"]\n",
      "Column[\"Region\"]\n",
      "Column[\"GLA\"]\n",
      "Column[\"Acquired date\"]\n",
      "Column[\"DIM 1\"]\n",
      "Column[\"Year\"]\n",
      "Column[\"Currency\"]\n",
      "Column[\"Jan\"]\n",
      "Column[\"Feb\"]\n",
      "Column[\"Mar\"]\n",
      "Column[\"Apr\"]\n",
      "Column[\"May\"]\n",
      "Column[\"Jun\"]\n",
      "Column[\"Jul\"]\n",
      "Column[\"Aug\"]\n",
      "Column[\"Sep\"]\n",
      "Column[\"Oct\"]\n",
      "Column[\"Nov\"]\n",
      "Column[\"Dec\"]\n",
      "Column[\"Total Revenue\"]\n",
      "Column[\"CompanyCode\"]\n"
     ]
    }
   ],
   "source": [
    "all_tables = snowpark.sql(f\"SHOW TABLES IN {db_name}.{schema_name}\").collect()\n",
    "\n",
    "table_names = [row[\"name\"] for row in all_tables]\n",
    "\n",
    "download_folder_path = os.path.expanduser(\"~\" + os.path.sep + \"Downloads\")\n",
    "report_path = os.path.join(download_folder_path, 'Data_Quality_Report.xlsx')\n",
    "\n",
    "for table_name in table_names:\n",
    "    if(table_name == 'COHORT_STAGING_MASTER_DATA'):\n",
    "        \n",
    "        if(len(workbook.sheetnames) == 1):\n",
    "            new_worksheet = workbook.active\n",
    "            new_worksheet.title = table_name\n",
    "        else:\n",
    "            new_worksheet = workbook.create_sheet(title = table_name)\n",
    "        \n",
    "        report_summary = data_quality_check(table_name)\n",
    "    \n",
    "    # show(report = report_summary)\n",
    "    \n",
    "    new_worksheet = write_to_excel_file(new_worksheet,report_summary,)\n",
    "    \n",
    "downloads_folder = os.path.expanduser(\"~\" + os.path.sep + \"Downloads\")\n",
    "file_path = os.path.join(downloads_folder,'Data_Quality_Report_'+schema_name+\"(\"+str(datetime.now().strftime(\"%d-%m-%Y\"))+').xlsx')\n",
    "workbook.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "Worksheet not created for :  set()\n",
      "Unwanted worksheet : {'COHORT_STAGING_MASTER_DATA'}\n"
     ]
    }
   ],
   "source": [
    "#Validation\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "workbook = load_workbook(file_path)\n",
    "\n",
    "# Get the number of sheets\n",
    "number_of_sheets = len(workbook.sheetnames)\n",
    "\n",
    "snowpark.sql(\"USE {db_name};\")\n",
    "snowflake_tables = list(snowpark.sql(\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = '{schema_name}';\").collect())\n",
    "\n",
    "excel_sheets = list(workbook.sheetnames)\n",
    "\n",
    "print(len(snowflake_tables),len(excel_sheets))\n",
    "\n",
    "print(\"Worksheet not created for : \",set(snowflake_tables)-set(excel_sheets))\n",
    "print(\"Unwanted worksheet :\", set(excel_sheets)-set(snowflake_tables))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dqenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
